[![author](https://img.shields.io/badge/author-dfedeoli-red.svg)](https://www.linkedin.com/in/danilo-ferreira-de-oliveira) [![](https://img.shields.io/badge/python-3.7+-blue.svg)](https://www.python.org/downloads/release/python-365/) [![GPLv3 license](https://img.shields.io/badge/License-GPLv3-blue.svg)](http://perso.crans.org/besson/LICENSE.html)

<p align="center">
  <img src="banner2.png" >
</p>

# Danilo Ferreira de Oliveira
<sub>*Data Engineer/Analytics Engineer*</sub>

Graduado em Engenharia Mecânica pela UnB, me encontrei na ciência de dados por paixão à matemática e habilidade com lógica e programação. Pós-graduado em Ciência de Dados e Inteligência Artificial pela PUCRS e atualmente trabalhando na ília como Data Engineer/Analytics Engineer. Experiência com construção de pipelines de dados usando serviços da AWS (S3, Lambda, Glue, Athena, API Gateway, Step Functions) e com construção de dashboards (Quicksight, Power BI, Apache Superset). Atuação com Notebooks Databricks, Azure Data Factory, ADLS Gen 2, Bancos de dados relacionais (MySQL, PostgreSQL) e Pyspark. 

Determinado a contribuir positivamente para a atual transformação digital, de forma que possamos viver uma saudável era dos dados e da inteligência artificial. [LinkedIn](https://www.linkedin.com/in/danilo-ferreira-de-oliveira), [Currículo](https://drive.google.com/file/d/1bTnCSfwXT0VrejzRy66PNLolt2bNZNZG/view?usp=sharing)

**Habilidades/Competências:** Python, SQL, ETL e AWS.

---

## Projetos:

### Streaming Smartphone Data through Kafka with Google Compute Engine and BigQuery

Disponível em: https://github.com/dfedeoli/kafka-gce-smartphone-data

Streaming de dados de acelerômetro de um celular, através de código python e broker Kafka no Google Compute Engine, com armazenamento no Google Cloud Storage e disponibilização no BigQuery.

### Modern Data Stack Pipeline

Disponível em: https://github.com/dfedeoli/mds-pipeline

Implementação de um pipeline completo de dados, utilizando ferramentas da Modern Data Stack. Foram utilizados: Airbyte, Airflow, dbt, snowflake e Metabase.

### Recommendation Systems: Rating Predictions with _MovieLens_ data

Disponível em: https://github.com/dfedeoli/recommendation-system.

Construção de um algoritmo para predição de avaliações de filmes feitas por usuários, base de sistemas de recomendação. Primeiro projeto do último curso do [Certificado Profissional em Data Science HarvardX](https://www.edx.org/professional-certificate/harvardx-data-science), ministrado pelo Professor Rafael Irrizarry ([@rafalab](https://rafalab.github.io)). Executado totalmente em Linguagem R, aborda desde a obtenção e análise dos dados até o teste de algoritmos de Machine Learning, por meio de avaliação dos valores RMSE (Root Mean Square Error).

### Term Deposits Subscription Analysis for a Portuguese Bank 

Disponível em: https://github.com/dfedeoli/bank-marketing

Construção de modelos para predição de assinatura de termos de depósito de um banco português, usando como _features_ do modelo dados sobre as abordagens de Marketing do banco. Dataset obtido a partir do UCI Machine Learning Repository.

### Maratona Behind The Code 2020

[Maratona](https://maratona.dev/pt) de Ciência de Dados, Inteligência Artificial e IoT, organizada pela IBM e composta por 8 desafios, abrangendo desde aprendizado de máquina em Jupyter Notebooks (linguagem Python) até a utilização de diversos serviços e softwares da IBM Cloud, como *Watson Speech to Text*, *Natural Language Understanding* e *Knowledge Studio*. **Classificação na Maratona: 53ª colocação (Ranking Brasil)**. 

* **Desafio 2 - UNINASSAU (Modelo de *Machine Learning* para assistência de alunos)**: http://bit.ly/39lnhra
* **Desafio 4 - Algar (Modelo de seleção de candidatos para contratação)**: https://bit.ly/310scZq
* **Desafio 6 - LIT (Segmentação de alunos para experiência personalizada)**: http://bit.ly/30aUyji
* **Desafio 7 - TNT (Previsão de recarga de *Vending Machines* em São Paulo)**: http://bit.ly/3ee0BM8

---

## Atividades de Cursos:

### AWS Computer Vision: Getting Started with GluonCV

Notebooks do [curso](https://www.coursera.org/learn/aws-computer-vision-gluoncv) disponível na plataforma de ensino **Coursera**, aplicando conceitos de Deep Learning e Visão Computacional em Python.

* **Module 3 Assignment: Tennis Ball Detector**  http://bit.ly/39kv7RT
* **Module 4 Assignment: Neural Network for Image Classification** http://bit.ly/2KUjBDo
* **Module 5 Practice Assessment 1: Deep Learning Data Concepts** http://bit.ly/3qXoJ8S
* **Module 5 Practice Assessment 2: MXNet Model Evaluation** http://bit.ly/3iMWuqG
* **Module 5 Assignment: MXNet Full Training Process** http://bit.ly/2KPr5Ya
* **Module 6 Assignment: Counting People in Images** http://bit.ly/2M6Tqd9

### Bootcamp Cientista de Dados - IGTI

Notebooks em Python (Google Colab e Databricks) do módulo final do Bootcamp Cientista de Dados, promovido pelo Instituto de Gestão e Tecnologia da Informação.

* **Trabalho Prático 1 do Módulo 4: Gasto anual total de consumidores locais**: http://bit.ly/3iQIGM3
* **Trabalho Prático 2 do Módulo 4: Poder de consumo de clientes de um Shopping** (Databricks): http://bit.ly/3iPQpdg
* **Desafio Final: Dados de Vítimas de AVCs** (Databricks): http://bit.ly/3prj0b4

---





